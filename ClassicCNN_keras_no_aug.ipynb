{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    MaxPooling2D,\n",
    "    Conv2D,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "\n",
    "from src.kerasCNN import *\n",
    "from src.augmentations.CustomAugmentations import CustomAugmentationsTF\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "os.mkdir(\"../models\")\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 32, 32\n",
    "batch_size = 64\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented are aleady trained models\n",
    "\n",
    "net_configs = [\n",
    "    # {\"kernel_sizes\":[3],\n",
    "    # \"num_filters\":[32],\n",
    "    # \"fc_sizes\":[128],},\n",
    "    # {\"kernel_sizes\":[3, 3],\n",
    "    # \"num_filters\":[32, 64],\n",
    "    # \"fc_sizes\":[128, 64],},\n",
    "    # {\"kernel_sizes\":[3, 3, 3],\n",
    "    # \"num_filters\":[32, 64, 64],\n",
    "    # \"fc_sizes\":[128, 64, 64],},\n",
    "    # {\"kernel_sizes\":[5],\n",
    "    # \"num_filters\":[32],\n",
    "    # \"fc_sizes\":[128],},\n",
    "    # {\"kernel_sizes\":[5, 5],\n",
    "    # \"num_filters\":[32, 64],\n",
    "    # \"fc_sizes\":[128, 64],},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config in tqdm(net_configs, desc=\"Configurations\"):\n",
    "    config_str = \"_\".join([f\"{k}_{v}\" for k, v in config.items()])\n",
    "\n",
    "    print(f\"Running config {config_str}\")\n",
    "\n",
    "    histories = list()\n",
    "    accuracies = list()\n",
    "    class_accuracies = list()\n",
    "    conf_mats = list()\n",
    "\n",
    "    for i in tqdm(range(5), desc=\"Iteration\"):\n",
    "        train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"../data/CINIC10/train\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            class_names=None,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=64,\n",
    "            image_size=(height, width),\n",
    "            shuffle=True,\n",
    "            seed=i,\n",
    "            validation_split=0.05,\n",
    "            subset=\"training\",\n",
    "        )\n",
    "\n",
    "        val_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"../data/CINIC10/valid\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            class_names=None,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=64,\n",
    "            image_size=(height, width),\n",
    "            shuffle=True,\n",
    "            seed=i,\n",
    "            validation_split=0.05,\n",
    "            subset=\"validation\",\n",
    "        )\n",
    "\n",
    "        test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"../data/CINIC10/test\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            class_names=None,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=64,\n",
    "            image_size=(height, width),\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        dnn_model = create_cnn(**config)\n",
    "\n",
    "        print(f\"Fitting model {i}\")\n",
    "        history = dnn_model.fit(train_set, validation_data=val_set, epochs=40)\n",
    "\n",
    "        print(f\"Predicting model {i}\")\n",
    "        preds = dnn_model.predict(test_set, verbose=2)\n",
    "        preds = preds.argmax(axis=1)\n",
    "        classes = test_set.class_names\n",
    "        test_labels = list()\n",
    "        for images, labels in test_set:\n",
    "            class_labels = [int(label) for label in labels]\n",
    "            test_labels.extend(class_labels)\n",
    "        test_labels = np.array(test_labels)\n",
    "\n",
    "        conf_mat = confusion_matrix(test_labels, preds)\n",
    "        accuracy = accuracy_score(test_labels, preds)\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        class_accuracy = conf_mat.diagonal() / conf_mat.sum(axis=1)\n",
    "\n",
    "        print(f\"Saving model {i}\")\n",
    "        dnn_model.save(f\"../models/ClassicCNN_{config_str}_no_aug_iter{i}.h5\")\n",
    "        histories.append(deepcopy(history.history))\n",
    "        accuracies.append(accuracy)\n",
    "        class_accuracies.append(class_accuracy)\n",
    "        conf_mats.append(conf_mat)\n",
    "\n",
    "    # save histories\n",
    "    with open(f\"results/HISTORY_ClassicCNN_{config_str}_no_aug.pkl\", \"wb\") as f:\n",
    "        pickle.dump(histories, f)\n",
    "\n",
    "    # save accuracies\n",
    "    with open(f\"results/ACCURACY_ClassicCNN_{config_str}_no_aug.pkl\", \"wb\") as f:\n",
    "        pickle.dump(accuracies, f)\n",
    "\n",
    "    # save class accuracies\n",
    "    with open(f\"results/CLASS_ACCURACY_ClassicCNN_{config_str}_no_aug.pkl\", \"wb\") as f:\n",
    "        pickle.dump(class_accuracies, f)\n",
    "\n",
    "    # save confusion matrices\n",
    "    with open(f\"results/CONF_MAT_ClassicCNN_{config_str}_no_aug.pkl\", \"wb\") as f:\n",
    "        pickle.dump(conf_mats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from results folder import all the  where filename contains [\"ACCURACY\", \"ClassicCNN\"]\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "files = os.listdir(\"results\")\n",
    "files = [f for f in files if \"ACCURACY\" in f and \"ClassicCNN\" in f]\n",
    "\n",
    "results = dict()\n",
    "for f in files:\n",
    "    with open(f\"results/{f}\", \"rb\") as f:\n",
    "        results[f] = pickle.load(f)\n",
    "\n",
    "# get the best model\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_config = None\n",
    "\n",
    "for k, v in results.items():\n",
    "    accuracy = np.mean(v)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = k.name.split(\"_\")[1]\n",
    "        best_config = k.name.split(\"_\")[2:]\n",
    "\n",
    "print(\n",
    "    f\"Best model is {best_model} with accuracy {best_accuracy} and config {best_config}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
