{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from src.augmentations import CustomAugmentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width=32,32\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2048)              4196352   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,892,490\n",
      "Trainable params: 29,839,370\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import Sequential from keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "dnn_model = Sequential()\n",
    "imported_model= tf.keras.applications.EfficientNetV2L (include_top=False,\n",
    "input_shape=(height,width,3),\n",
    "pooling='max',classes=10,\n",
    "weights='imagenet')\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "dnn_model.add(imported_model)\n",
    "dnn_model.add(Flatten())\n",
    "dnn_model.add(Dense(2048, activation='relu'))\n",
    "dnn_model.add(Dense(1024, activation='relu'))\n",
    "dnn_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "dnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adamm\\miniconda3\\envs\\py310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "dnn_model.compile(optimizer=Adam(lr=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../data/CINIC10/train',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(height, width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.05,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../data/CINIC10/valid',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(height, width),\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.05,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../data/CINIC10/test',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(height, width),\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m class_accuracies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m      9\u001b[0m conf_mats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitting model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m     history \u001b[38;5;241m=\u001b[39m dnn_model\u001b[38;5;241m.\u001b[39mfit(train_set, validation_data\u001b[38;5;241m=\u001b[39mval_set, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adamm\\miniconda3\\envs\\py310\\lib\\site-packages\\tqdm\\notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adamm\\miniconda3\\envs\\py310\\lib\\site-packages\\tqdm\\notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "histories = list()\n",
    "accuracies = list()\n",
    "class_accuracies = list()\n",
    "conf_mats = list()\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    print(f'Fitting model {i}')\n",
    "    history = dnn_model.fit(train_set, validation_data=val_set, epochs=25)\n",
    "\n",
    "    print(f'Predicting model {i}')\n",
    "    preds = dnn_model.predict(test_set, verbose=2)\n",
    "    preds = preds.argmax(axis=1)\n",
    "    classes = test_set.class_names\n",
    "    test_labels = list()\n",
    "    for images, labels in test_set:\n",
    "        class_labels = [int(label) for label in labels]\n",
    "        test_labels.extend(class_labels)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    conf_mat = confusion_matrix(test_labels, preds)\n",
    "    accuracy = accuracy_score(test_labels, preds)\n",
    "    class_accuracy = conf_mat.diagonal()/conf_mat.sum(axis=1)\n",
    "\n",
    "    print(f'Saving model {i}')\n",
    "    dnn_model.save(f'../models/EfficientNetV2L_no_aug_{i}.h5')\n",
    "    histories.append(deepcopy(history.history))\n",
    "    accuracies.append(accuracy)\n",
    "    class_accuracies.append(class_accuracy)\n",
    "    conf_mats.append(conf_mat)\n",
    "\n",
    "    \n",
    "# save histories\n",
    "import pickle\n",
    "with open('../models/HISTORY_EfficientNetV2L_no_aug.pkl', 'wb') as f:\n",
    "    pickle.dump(histories, f)\n",
    "\n",
    "# save accuracies\n",
    "with open('../models/ACCURACY_EfficientNetV2L_no_aug.pkl', 'wb') as f:\n",
    "    pickle.dump(accuracies, f)\n",
    "\n",
    "# save class accuracies\n",
    "with open('../models/CLASS_ACCURACY_EfficientNetV2L_no_aug.pkl', 'wb') as f:\n",
    "    pickle.dump(class_accuracies, f)\n",
    "\n",
    "# save confusion matrices\n",
    "with open('../models/CONF_MAT_EfficientNetV2L_no_aug.pkl', 'wb') as f:\n",
    "    pickle.dump(conf_mats, f)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
