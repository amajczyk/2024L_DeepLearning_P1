{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from src.augmentations import CustomAugmentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width=32,32\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517e7b5c496443f0a7692cad52b7bd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 0\n",
      "Epoch 1/25\n",
      "1336/1336 [==============================] - 57s 37ms/step - loss: 1.4130 - accuracy: 0.5066 - val_loss: 1.6718 - val_accuracy: 0.4489\n",
      "Epoch 2/25\n",
      "1336/1336 [==============================] - 49s 37ms/step - loss: 1.1578 - accuracy: 0.5972 - val_loss: 1.4483 - val_accuracy: 0.4840\n",
      "Epoch 3/25\n",
      " 973/1336 [====================>.........] - ETA: 12s - loss: 1.0695 - accuracy: 0.6264"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "\n",
    "histories = list()\n",
    "accuracies = list()\n",
    "class_accuracies = list()\n",
    "conf_mats = list()\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../data/CINIC10/train',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    image_size=(height, width),\n",
    "    shuffle=True,\n",
    "    seed=i,\n",
    "    validation_split=0.05,\n",
    "    subset='training'\n",
    "    )\n",
    "\n",
    "    val_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        '../data/CINIC10/valid',\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        class_names=None,\n",
    "        color_mode='rgb',\n",
    "        batch_size=64,\n",
    "        image_size=(height, width),\n",
    "        shuffle=True,\n",
    "        seed=i,\n",
    "        validation_split=0.05,\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        '../data/CINIC10/test',\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        class_names=None,\n",
    "        color_mode='rgb',\n",
    "        batch_size=64,\n",
    "        image_size=(height, width),\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "\n",
    "    dnn_model = Sequential()\n",
    "    imported_model= tf.keras.applications.ResNet50 (include_top=False,\n",
    "    input_shape=(height,width,3),\n",
    "    pooling='max',classes=10,\n",
    "    weights='imagenet')\n",
    "\n",
    "    dnn_model.add(imported_model)\n",
    "    dnn_model.add(Flatten())\n",
    "    dnn_model.add(Dense(2048, activation='relu'))\n",
    "    dnn_model.add(Dense(1024, activation='relu'))\n",
    "    dnn_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    dnn_model.compile(optimizer=Adam(learning_rate=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    print(f'Fitting model {i}')\n",
    "    history = dnn_model.fit(train_set, validation_data=val_set, epochs=25)\n",
    "\n",
    "    print(f'Predicting model {i}')\n",
    "    preds = dnn_model.predict(test_set, verbose=2)\n",
    "    preds = preds.argmax(axis=1)\n",
    "    classes = test_set.class_names\n",
    "    test_labels = list()\n",
    "    for images, labels in test_set:\n",
    "        class_labels = [int(label) for label in labels]\n",
    "        test_labels.extend(class_labels)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    conf_mat = confusion_matrix(test_labels, preds)\n",
    "    accuracy = accuracy_score(test_labels, preds)\n",
    "    class_accuracy = conf_mat.diagonal()/conf_mat.sum(axis=1)\n",
    "\n",
    "    print(f'Saving model {i}')\n",
    "    dnn_model.save(f'../models/resnet50_no_aug_{i}.h5')\n",
    "    histories.append(deepcopy(history.history))\n",
    "    accuracies.append(accuracy)\n",
    "    class_accuracies.append(class_accuracy)\n",
    "    conf_mats.append(conf_mat)\n",
    "\n",
    "    \n",
    "# save histories\n",
    "import pickle\n",
    "with open('../results/HISTORY_resnet50_no_aug.pkl', 'wb') as f:\n",
    "    pickle.dump(histories, f)\n",
    "\n",
    "# save accuracies\n",
    "with open('../results/ACCURACY_resnet50_no_aug.pkl', 'wb') as f:\n",
    "    pickle.dump(accuracies, f)\n",
    "\n",
    "# save class accuracies\n",
    "with open('../results/CLASS_ACCURACY_resnet50_no_aug.pkl', 'wb') as f:\n",
    "    pickle.dump(class_accuracies, f)\n",
    "\n",
    "# save confusion matrices\n",
    "with open('../results/CONF_MAT_resnet50_no_aug.pkl', 'wb') as f:\n",
    "    pickle.dump(conf_mats, f)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
