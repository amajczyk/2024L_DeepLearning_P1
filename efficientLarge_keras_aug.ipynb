{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from src.augmentations import CustomAugmentations\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "# tf.config.experimental.enable_op_determinism()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width=32,32\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'flip': 0.5, 'gauss_noise': 0.5}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.augmentations.CustomAugmentations import CustomAugmentationsTF\n",
    "\n",
    "# Define the augmentation probabilities\n",
    "p_dict = {\n",
    "  \"flip\": 0.5,\n",
    "  # \"transpose\": 0.5,\n",
    "  \"gauss_noise\": 0.5,\n",
    "  # \"brightness_contrast\": 0.5,\n",
    "  # \"hue_saturation_value\": 0.5,\n",
    "}\n",
    "\n",
    "p_dicts = []\n",
    "# for aug_type in p_dict.keys():\n",
    "#     p_d = {aug_type: .5}\n",
    "#     p_dicts.append(p_d)\n",
    "\n",
    "# p_dict = {\n",
    "#   \"flip\": 0.5,\n",
    "#   \"transpose\": 0.5,\n",
    "#   \"gauss_noise\": 0.5,\n",
    "#   \"brightness_contrast\": 0.5,\n",
    "#   \"hue_saturation_value\": 0.5 ,\n",
    "# }\n",
    "p_dicts.append(p_dict)\n",
    "\n",
    "p_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "augmented = original_dataset.map(lambda image, label: (custom_aug.augment(image), label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da2be3fc4b94641b98f7d8262cdeb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmentation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentations: flip0.5_gauss_noise0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baeaade73d2844769f4d088936b3be08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50e2f636dd74c9ea5e244178f3c91f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1336/1336 [==============================] - 245s 161ms/step - loss: 1.2966 - accuracy: 0.5414 - val_loss: 0.9992 - val_accuracy: 0.6458\n",
      "Epoch 2/20\n",
      "1336/1336 [==============================] - 206s 154ms/step - loss: 1.0517 - accuracy: 0.6353 - val_loss: 1.0433 - val_accuracy: 0.6278\n",
      "Epoch 3/20\n",
      "1336/1336 [==============================] - 208s 156ms/step - loss: 0.9642 - accuracy: 0.6638 - val_loss: 0.9341 - val_accuracy: 0.6978\n",
      "Epoch 4/20\n",
      "1336/1336 [==============================] - 208s 155ms/step - loss: 0.8367 - accuracy: 0.7092 - val_loss: 0.8425 - val_accuracy: 0.7180\n",
      "Epoch 5/20\n",
      "1336/1336 [==============================] - 208s 156ms/step - loss: 0.6783 - accuracy: 0.7665 - val_loss: 0.8741 - val_accuracy: 0.6996\n",
      "Epoch 6/20\n",
      "1336/1336 [==============================] - 209s 156ms/step - loss: 0.5741 - accuracy: 0.8019 - val_loss: 0.9393 - val_accuracy: 0.7031\n",
      "Epoch 7/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.7171 - accuracy: 0.7533 - val_loss: 0.7225 - val_accuracy: 0.7502\n",
      "Epoch 8/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.5580 - accuracy: 0.8083 - val_loss: 0.7580 - val_accuracy: 0.7422\n",
      "Epoch 9/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.4704 - accuracy: 0.8390 - val_loss: 0.8128 - val_accuracy: 0.7420\n",
      "Epoch 10/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.5385 - accuracy: 0.8159 - val_loss: 0.7352 - val_accuracy: 0.7476\n",
      "Epoch 11/20\n",
      "1336/1336 [==============================] - 209s 156ms/step - loss: 0.3903 - accuracy: 0.8665 - val_loss: 0.8766 - val_accuracy: 0.7402\n",
      "Epoch 12/20\n",
      "1336/1336 [==============================] - 208s 155ms/step - loss: 0.4353 - accuracy: 0.8506 - val_loss: 0.7469 - val_accuracy: 0.7618\n",
      "Epoch 13/20\n",
      "1336/1336 [==============================] - 208s 156ms/step - loss: 0.3269 - accuracy: 0.8887 - val_loss: 0.8471 - val_accuracy: 0.7460\n",
      "Epoch 14/20\n",
      "1336/1336 [==============================] - 208s 156ms/step - loss: 0.2425 - accuracy: 0.9202 - val_loss: 0.9333 - val_accuracy: 0.7376\n",
      "Epoch 15/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.1969 - accuracy: 0.9358 - val_loss: 0.9826 - val_accuracy: 0.7467\n",
      "Epoch 16/20\n",
      "1336/1336 [==============================] - 206s 154ms/step - loss: 0.3883 - accuracy: 0.8672 - val_loss: 0.7763 - val_accuracy: 0.7618\n",
      "Epoch 17/20\n",
      "1336/1336 [==============================] - 208s 156ms/step - loss: 0.2039 - accuracy: 0.9323 - val_loss: 0.9890 - val_accuracy: 0.7469\n",
      "Epoch 18/20\n",
      "1336/1336 [==============================] - 209s 156ms/step - loss: 0.3113 - accuracy: 0.8945 - val_loss: 1.0135 - val_accuracy: 0.7547\n",
      "Epoch 19/20\n",
      "1336/1336 [==============================] - 209s 156ms/step - loss: 0.1899 - accuracy: 0.9365 - val_loss: 0.9796 - val_accuracy: 0.7547\n",
      "Epoch 20/20\n",
      "1336/1336 [==============================] - 210s 157ms/step - loss: 0.1623 - accuracy: 0.9474 - val_loss: 1.0132 - val_accuracy: 0.7520\n",
      "Predicting model 0\n",
      "1407/1407 - 62s - 62s/epoch - 44ms/step\n",
      "Accuracy: 0.7567333333333334 for model 0\n",
      "Saving model 0\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762644e63c9047a4b6bf3074cc050de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1336/1336 [==============================] - 239s 157ms/step - loss: 1.3233 - accuracy: 0.5259 - val_loss: 1.1120 - val_accuracy: 0.6078\n",
      "Epoch 2/20\n",
      "1336/1336 [==============================] - 206s 154ms/step - loss: 1.1436 - accuracy: 0.6030 - val_loss: 1.0652 - val_accuracy: 0.6264\n",
      "Epoch 3/20\n",
      "1336/1336 [==============================] - 204s 153ms/step - loss: 1.0796 - accuracy: 0.6245 - val_loss: 1.1537 - val_accuracy: 0.5849\n",
      "Epoch 4/20\n",
      "1336/1336 [==============================] - 205s 154ms/step - loss: 1.1198 - accuracy: 0.6019 - val_loss: 0.9694 - val_accuracy: 0.6547\n",
      "Epoch 5/20\n",
      "1336/1336 [==============================] - 205s 154ms/step - loss: 0.9494 - accuracy: 0.6682 - val_loss: 1.0972 - val_accuracy: 0.6164\n",
      "Epoch 6/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.9074 - accuracy: 0.6807 - val_loss: 0.8947 - val_accuracy: 0.6876\n",
      "Epoch 7/20\n",
      "1336/1336 [==============================] - 208s 155ms/step - loss: 0.9599 - accuracy: 0.6633 - val_loss: 1.0192 - val_accuracy: 0.6444\n",
      "Epoch 8/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.9071 - accuracy: 0.6839 - val_loss: 0.8824 - val_accuracy: 0.6822\n",
      "Epoch 9/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.8155 - accuracy: 0.7159 - val_loss: 0.7985 - val_accuracy: 0.7260\n",
      "Epoch 10/20\n",
      "1336/1336 [==============================] - 209s 156ms/step - loss: 0.6867 - accuracy: 0.7608 - val_loss: 0.7833 - val_accuracy: 0.7398\n",
      "Epoch 11/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.5788 - accuracy: 0.7993 - val_loss: 0.7942 - val_accuracy: 0.7389\n",
      "Epoch 12/20\n",
      "1336/1336 [==============================] - 208s 156ms/step - loss: 0.6190 - accuracy: 0.7824 - val_loss: 0.8336 - val_accuracy: 0.7264\n",
      "Epoch 13/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.6616 - accuracy: 0.7698 - val_loss: 0.7164 - val_accuracy: 0.7493\n",
      "Epoch 14/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.5335 - accuracy: 0.8145 - val_loss: 0.7592 - val_accuracy: 0.7424\n",
      "Epoch 15/20\n",
      "1336/1336 [==============================] - 201s 150ms/step - loss: 0.4583 - accuracy: 0.8410 - val_loss: 0.7765 - val_accuracy: 0.7480\n",
      "Epoch 16/20\n",
      "1336/1336 [==============================] - 201s 150ms/step - loss: 0.5043 - accuracy: 0.8239 - val_loss: 0.7400 - val_accuracy: 0.7584\n",
      "Epoch 17/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.4189 - accuracy: 0.8541 - val_loss: 1.2367 - val_accuracy: 0.7460\n",
      "Epoch 18/20\n",
      "1336/1336 [==============================] - 201s 151ms/step - loss: 0.3010 - accuracy: 0.8972 - val_loss: 0.8820 - val_accuracy: 0.7429\n",
      "Epoch 19/20\n",
      "1336/1336 [==============================] - 201s 151ms/step - loss: 0.4410 - accuracy: 0.8473 - val_loss: 0.8092 - val_accuracy: 0.7442\n",
      "Epoch 20/20\n",
      "1336/1336 [==============================] - 205s 153ms/step - loss: 0.3055 - accuracy: 0.8971 - val_loss: 0.8534 - val_accuracy: 0.7544\n",
      "Predicting model 1\n",
      "1407/1407 - 64s - 64s/epoch - 45ms/step\n",
      "Accuracy: 0.7496333333333334 for model 1\n",
      "Saving model 1\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c28a8a7ac244f68aa35be935807f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1336/1336 [==============================] - 239s 156ms/step - loss: 1.2149 - accuracy: 0.5708 - val_loss: 0.9587 - val_accuracy: 0.6676\n",
      "Epoch 2/20\n",
      "1336/1336 [==============================] - 214s 160ms/step - loss: 1.0821 - accuracy: 0.6210 - val_loss: 1.1653 - val_accuracy: 0.6020\n",
      "Epoch 3/20\n",
      "1336/1336 [==============================] - 211s 158ms/step - loss: 1.0102 - accuracy: 0.6480 - val_loss: 1.0233 - val_accuracy: 0.6380\n",
      "Epoch 4/20\n",
      "1336/1336 [==============================] - 205s 153ms/step - loss: 0.9437 - accuracy: 0.6716 - val_loss: 0.8257 - val_accuracy: 0.7044\n",
      "Epoch 5/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.7567 - accuracy: 0.7389 - val_loss: 0.7948 - val_accuracy: 0.7249\n",
      "Epoch 6/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.8498 - accuracy: 0.7040 - val_loss: 0.9739 - val_accuracy: 0.6540\n",
      "Epoch 7/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.7966 - accuracy: 0.7231 - val_loss: 0.7596 - val_accuracy: 0.7291\n",
      "Epoch 8/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.6876 - accuracy: 0.7627 - val_loss: 0.8045 - val_accuracy: 0.7300\n",
      "Epoch 9/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.7026 - accuracy: 0.7567 - val_loss: 0.8492 - val_accuracy: 0.7178\n",
      "Epoch 10/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.5819 - accuracy: 0.7999 - val_loss: 0.8442 - val_accuracy: 0.7407\n",
      "Epoch 11/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.4380 - accuracy: 0.8518 - val_loss: 0.9119 - val_accuracy: 0.7262\n",
      "Epoch 12/20\n",
      "1336/1336 [==============================] - 204s 152ms/step - loss: 0.6958 - accuracy: 0.7603 - val_loss: 0.6874 - val_accuracy: 0.7580\n",
      "Epoch 13/20\n",
      "1336/1336 [==============================] - 204s 152ms/step - loss: 0.5464 - accuracy: 0.8123 - val_loss: 0.7008 - val_accuracy: 0.7522\n",
      "Epoch 14/20\n",
      "1336/1336 [==============================] - 204s 152ms/step - loss: 0.4466 - accuracy: 0.8460 - val_loss: 0.7706 - val_accuracy: 0.7518\n",
      "Epoch 15/20\n",
      "1336/1336 [==============================] - 201s 150ms/step - loss: 0.4466 - accuracy: 0.8480 - val_loss: 0.8331 - val_accuracy: 0.7618\n",
      "Epoch 16/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.3918 - accuracy: 0.8648 - val_loss: 1.3273 - val_accuracy: 0.7362\n",
      "Epoch 17/20\n",
      "1336/1336 [==============================] - 204s 152ms/step - loss: 0.4410 - accuracy: 0.8467 - val_loss: 1.1394 - val_accuracy: 0.7569\n",
      "Epoch 18/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.2750 - accuracy: 0.9065 - val_loss: 0.8847 - val_accuracy: 0.7562\n",
      "Epoch 19/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.2263 - accuracy: 0.9250 - val_loss: 0.9766 - val_accuracy: 0.7564\n",
      "Epoch 20/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.1805 - accuracy: 0.9400 - val_loss: 1.0029 - val_accuracy: 0.7513\n",
      "Predicting model 2\n",
      "1407/1407 - 68s - 68s/epoch - 49ms/step\n",
      "Accuracy: 0.7408111111111111 for model 2\n",
      "Saving model 2\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696dbb929791460cb14741d123b1d69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1336/1336 [==============================] - 237s 155ms/step - loss: 1.2698 - accuracy: 0.5474 - val_loss: 1.0642 - val_accuracy: 0.6267\n",
      "Epoch 2/20\n",
      "1336/1336 [==============================] - 203s 151ms/step - loss: 0.9425 - accuracy: 0.6725 - val_loss: 1.0421 - val_accuracy: 0.6260\n",
      "Epoch 3/20\n",
      "1336/1336 [==============================] - 201s 150ms/step - loss: 1.0028 - accuracy: 0.6495 - val_loss: 0.8861 - val_accuracy: 0.6862\n",
      "Epoch 4/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.8050 - accuracy: 0.7219 - val_loss: 0.8947 - val_accuracy: 0.6778\n",
      "Epoch 5/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.7294 - accuracy: 0.7471 - val_loss: 0.8095 - val_accuracy: 0.7216\n",
      "Epoch 6/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.7034 - accuracy: 0.7589 - val_loss: 0.8091 - val_accuracy: 0.7198\n",
      "Epoch 7/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.7585 - accuracy: 0.7378 - val_loss: 0.8054 - val_accuracy: 0.7124\n",
      "Epoch 8/20\n",
      "1336/1336 [==============================] - 201s 151ms/step - loss: 0.6853 - accuracy: 0.7617 - val_loss: 0.8345 - val_accuracy: 0.7087\n",
      "Epoch 9/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.6751 - accuracy: 0.7653 - val_loss: 0.7335 - val_accuracy: 0.7364\n",
      "Epoch 10/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.6245 - accuracy: 0.7853 - val_loss: 0.7162 - val_accuracy: 0.7482\n",
      "Epoch 11/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.5087 - accuracy: 0.8241 - val_loss: 0.7221 - val_accuracy: 0.7524\n",
      "Epoch 12/20\n",
      "1336/1336 [==============================] - 206s 154ms/step - loss: 0.4215 - accuracy: 0.8548 - val_loss: 0.7808 - val_accuracy: 0.7476\n",
      "Epoch 13/20\n",
      "1336/1336 [==============================] - 206s 154ms/step - loss: 0.5259 - accuracy: 0.8197 - val_loss: 0.7141 - val_accuracy: 0.7564\n",
      "Epoch 14/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.4369 - accuracy: 0.8517 - val_loss: 0.7930 - val_accuracy: 0.7433\n",
      "Epoch 15/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.4626 - accuracy: 0.8427 - val_loss: 0.6958 - val_accuracy: 0.7673\n",
      "Epoch 16/20\n",
      "1336/1336 [==============================] - 209s 157ms/step - loss: 0.3203 - accuracy: 0.8915 - val_loss: 0.8274 - val_accuracy: 0.7484\n",
      "Epoch 17/20\n",
      "1336/1336 [==============================] - 206s 154ms/step - loss: 0.3560 - accuracy: 0.8787 - val_loss: 0.7598 - val_accuracy: 0.7629\n",
      "Epoch 18/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.2767 - accuracy: 0.9071 - val_loss: 0.8596 - val_accuracy: 0.7544\n",
      "Epoch 19/20\n",
      "1336/1336 [==============================] - 208s 156ms/step - loss: 0.2968 - accuracy: 0.9005 - val_loss: 0.8221 - val_accuracy: 0.7500\n",
      "Epoch 20/20\n",
      "1336/1336 [==============================] - 205s 153ms/step - loss: 0.1996 - accuracy: 0.9357 - val_loss: 0.9269 - val_accuracy: 0.7482\n",
      "Predicting model 3\n",
      "1407/1407 - 60s - 60s/epoch - 43ms/step\n",
      "Accuracy: 0.7542888888888889 for model 3\n",
      "Saving model 3\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2be8ffd1e64dc2a6a8e72787f8044a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1336/1336 [==============================] - 241s 157ms/step - loss: 1.2585 - accuracy: 0.5508 - val_loss: 1.0167 - val_accuracy: 0.6567\n",
      "Epoch 2/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 1.1519 - accuracy: 0.5967 - val_loss: 0.9487 - val_accuracy: 0.6624\n",
      "Epoch 3/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 1.0652 - accuracy: 0.6283 - val_loss: 0.8909 - val_accuracy: 0.6916\n",
      "Epoch 4/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.9887 - accuracy: 0.6567 - val_loss: 1.1866 - val_accuracy: 0.6089\n",
      "Epoch 5/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 1.0209 - accuracy: 0.6426 - val_loss: 0.9165 - val_accuracy: 0.6829\n",
      "Epoch 6/20\n",
      "1336/1336 [==============================] - 204s 153ms/step - loss: 0.8856 - accuracy: 0.6911 - val_loss: 1.1293 - val_accuracy: 0.6596\n",
      "Epoch 7/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 1.0235 - accuracy: 0.6410 - val_loss: 1.0170 - val_accuracy: 0.6469\n",
      "Epoch 8/20\n",
      "1336/1336 [==============================] - 204s 153ms/step - loss: 0.8776 - accuracy: 0.6921 - val_loss: 1.3051 - val_accuracy: 0.6764\n",
      "Epoch 9/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.8107 - accuracy: 0.7181 - val_loss: 1.0255 - val_accuracy: 0.7051\n",
      "Epoch 10/20\n",
      "1336/1336 [==============================] - 206s 154ms/step - loss: 0.8561 - accuracy: 0.7010 - val_loss: 1.0354 - val_accuracy: 0.6836\n",
      "Epoch 11/20\n",
      "1336/1336 [==============================] - 207s 155ms/step - loss: 0.8553 - accuracy: 0.7009 - val_loss: 0.8525 - val_accuracy: 0.7033\n",
      "Epoch 12/20\n",
      "1336/1336 [==============================] - 206s 154ms/step - loss: 0.7582 - accuracy: 0.7335 - val_loss: 0.8102 - val_accuracy: 0.7222\n",
      "Epoch 13/20\n",
      "1336/1336 [==============================] - 206s 154ms/step - loss: 0.6090 - accuracy: 0.7871 - val_loss: 0.7662 - val_accuracy: 0.7449\n",
      "Epoch 14/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.6578 - accuracy: 0.7691 - val_loss: 0.7508 - val_accuracy: 0.7331\n",
      "Epoch 15/20\n",
      "1336/1336 [==============================] - 202s 151ms/step - loss: 0.5388 - accuracy: 0.8114 - val_loss: 0.8478 - val_accuracy: 0.7396\n",
      "Epoch 16/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.4314 - accuracy: 0.8509 - val_loss: 0.8310 - val_accuracy: 0.7398\n",
      "Epoch 17/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.5580 - accuracy: 0.8060 - val_loss: 0.7258 - val_accuracy: 0.7520\n",
      "Epoch 18/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.3760 - accuracy: 0.8699 - val_loss: 0.8031 - val_accuracy: 0.7467\n",
      "Epoch 19/20\n",
      "1336/1336 [==============================] - 203s 152ms/step - loss: 0.5288 - accuracy: 0.8169 - val_loss: 0.7603 - val_accuracy: 0.7433\n",
      "Epoch 20/20\n",
      "1336/1336 [==============================] - 205s 153ms/step - loss: 0.3396 - accuracy: 0.8836 - val_loss: 0.9037 - val_accuracy: 0.7456\n",
      "Predicting model 4\n",
      "1407/1407 - 69s - 69s/epoch - 49ms/step\n",
      "Accuracy: 0.7492666666666666 for model 4\n",
      "Saving model 4\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from src.kerasCNN import *\n",
    "import pickle\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "histories = list()\n",
    "accuracies = list()\n",
    "class_accuracies = list()\n",
    "conf_mats = list()\n",
    "\n",
    "for augs in tqdm(p_dicts, desc=\"Augmentation\"):\n",
    "    aug_str = \"_\".join([key + str(value) for key, value in augs.items()])\n",
    "    print(f\"Augmentations: {aug_str}\")\n",
    "\n",
    "    for iteration in tqdm(range(5), desc=\"Iteration\"):\n",
    "        train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"../data/CINIC10/train\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            class_names=None,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=batch_size,\n",
    "            image_size=(height, width),\n",
    "            shuffle=True,\n",
    "            seed=iteration,\n",
    "            validation_split=0.05,\n",
    "            subset=\"training\",\n",
    "        )\n",
    "\n",
    "        val_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"../data/CINIC10/valid\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            class_names=None,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=batch_size,\n",
    "            image_size=(height, width),\n",
    "            shuffle=True,\n",
    "            seed=iteration,\n",
    "            validation_split=0.05,\n",
    "            subset=\"validation\",\n",
    "        )\n",
    "\n",
    "        test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"../data/CINIC10/test\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            class_names=None,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=batch_size,\n",
    "            image_size=(height, width),\n",
    "            shuffle=False,\n",
    "        )\n",
    "        dnn_model = Sequential()\n",
    "        imported_model = tf.keras.applications.EfficientNetV2L(\n",
    "            include_top=False,\n",
    "            input_shape=(height, width, 3),\n",
    "            pooling=\"max\",\n",
    "            classes=10,\n",
    "            weights=\"imagenet\",\n",
    "        )\n",
    "        dnn_model.add(imported_model)\n",
    "        dnn_model.add(Flatten())\n",
    "        dnn_model.add(Dense(2048, activation=\"relu\"))\n",
    "        dnn_model.add(Dense(1024, activation=\"relu\"))\n",
    "        dnn_model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "        dnn_model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "    )\n",
    "       \n",
    "\n",
    "        history = {\n",
    "            \"loss\": list(),\n",
    "            \"accuracy\": list(),\n",
    "            \"val_loss\": list(),\n",
    "            \"val_accuracy\": list(),\n",
    "        }\n",
    "\n",
    "        print(f\"Fitting model {iteration}\")\n",
    "        for epoch in tqdm(range(EPOCHS), desc=\"Epoch\"):\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "            custom_aug = CustomAugmentationsTF(augs)\n",
    "            train_set_aug = train_set.map(lambda x, y: (custom_aug.augment(x), y))\n",
    "\n",
    "            hist_ = dnn_model.fit(train_set_aug, validation_data=val_set, epochs=1)\n",
    "            history[\"loss\"].append(hist_.history[\"loss\"])\n",
    "            history[\"accuracy\"].append(hist_.history[\"accuracy\"])\n",
    "            history[\"val_loss\"].append(hist_.history[\"val_loss\"])\n",
    "            history[\"val_accuracy\"].append(hist_.history[\"val_accuracy\"])\n",
    "\n",
    "        print(f\"Predicting model {iteration}\")\n",
    "        preds = dnn_model.predict(test_set, verbose=2)\n",
    "        preds = preds.argmax(axis=1)\n",
    "        classes = test_set.class_names\n",
    "        test_labels = list()\n",
    "        for images, labels in test_set:\n",
    "            class_labels = [int(label) for label in labels]\n",
    "            test_labels.extend(class_labels)\n",
    "        test_labels = np.array(test_labels)\n",
    "\n",
    "        conf_mat = confusion_matrix(test_labels, preds)\n",
    "        accuracy = accuracy_score(test_labels, preds)\n",
    "        print(f\"Accuracy: {accuracy} for model {iteration}\")\n",
    "        class_accuracy = conf_mat.diagonal() / conf_mat.sum(axis=1)\n",
    "\n",
    "        print(f\"Saving model {iteration}\")\n",
    "        dnn_model.save(f\"../models/EfficientNet_aug_{aug_str}_{iteration}.h5\")\n",
    "        histories.append(deepcopy(history))\n",
    "        accuracies.append(deepcopy(accuracy))\n",
    "        class_accuracies.append(deepcopy(class_accuracy))\n",
    "        conf_mats.append(deepcopy(conf_mat))\n",
    "\n",
    "\n",
    "    with open(f\"results/HISTORY_EfficientNet_aug_{aug_str}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(histories, f)\n",
    "\n",
    "    with open(f\"results/ACCURACY_EfficientNet_aug_{aug_str}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(accuracies, f)\n",
    "\n",
    "    with open(f\"results/CLASS_ACCURACY_EfficientNet_aug_{aug_str}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(class_accuracies, f)\n",
    "\n",
    "    with open(f\"results/CONF_MAT_EfficientNet_aug_{aug_str}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(conf_mats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
