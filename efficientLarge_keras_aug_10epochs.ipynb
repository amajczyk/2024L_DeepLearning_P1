{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from src.augmentations.CustomAugmentations import CustomAugmentationsTF\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "import os \n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "\n",
    "keras.utils.set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width=32,32\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'gauss_noise': 0.5}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the augmentation probabilities\n",
    "p_dict = {\n",
    "  # \"flip\": 0.5,\n",
    "  # \"transpose\": 0.5,\n",
    "  \"gauss_noise\": 0.5,\n",
    "  # \"brightness_contrast\": 0.5,\n",
    "  # \"hue_saturation_value\": 0.5,\n",
    "}\n",
    "\n",
    "p_dicts = []\n",
    "# for aug_type in p_dict.keys():\n",
    "#     p_d = {aug_type: .5}\n",
    "#     p_dicts.append(p_d)\n",
    "\n",
    "# p_dict = {\n",
    "#   \"flip\": 0.5,\n",
    "#   # \"transpose\": 0.5,\n",
    "#   \"gauss_noise\": 0.5,\n",
    "#   # \"brightness_contrast\": 0.5,\n",
    "#   # \"hue_saturation_value\": 0.5,\n",
    "# }\n",
    "# p_dicts.append(p_dict)\n",
    "\n",
    "p_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d12e9e715845fab6e25e74d69e2744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Augmentation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentations: gauss_noise0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05041154d6b54872b2e9f3d63e95f0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1430e73b4e554e3e9b6bdbb4ff9621ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "1336/1336 [==============================] - 236s 152ms/step - loss: 1.2586 - accuracy: 0.5613 - val_loss: 0.9984 - val_accuracy: 0.6489\n",
      "Epoch 2/13\n",
      "1336/1336 [==============================] - 199s 149ms/step - loss: 0.9186 - accuracy: 0.6885 - val_loss: 0.9233 - val_accuracy: 0.6856\n",
      "Epoch 3/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.8314 - accuracy: 0.7157 - val_loss: 1.7069 - val_accuracy: 0.4813\n",
      "Epoch 4/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 1.0224 - accuracy: 0.6467 - val_loss: 0.9252 - val_accuracy: 0.6853\n",
      "Epoch 5/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.8104 - accuracy: 0.7206 - val_loss: 0.8849 - val_accuracy: 0.7027\n",
      "Epoch 6/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.6465 - accuracy: 0.7778 - val_loss: 0.8777 - val_accuracy: 0.7096\n",
      "Epoch 7/13\n",
      "1336/1336 [==============================] - 194s 145ms/step - loss: 0.5563 - accuracy: 0.8125 - val_loss: 0.9730 - val_accuracy: 0.6733\n",
      "Epoch 8/13\n",
      "1336/1336 [==============================] - 190s 142ms/step - loss: 0.4920 - accuracy: 0.8343 - val_loss: 0.8596 - val_accuracy: 0.7169\n",
      "Epoch 9/13\n",
      "1336/1336 [==============================] - 190s 142ms/step - loss: 0.3559 - accuracy: 0.8818 - val_loss: 0.9564 - val_accuracy: 0.7118\n",
      "Epoch 10/13\n",
      "1336/1336 [==============================] - 190s 142ms/step - loss: 0.2938 - accuracy: 0.9032 - val_loss: 0.9668 - val_accuracy: 0.7173\n",
      "Epoch 11/13\n",
      "1336/1336 [==============================] - 191s 143ms/step - loss: 0.2670 - accuracy: 0.9134 - val_loss: 0.9662 - val_accuracy: 0.7251\n",
      "Epoch 12/13\n",
      "1336/1336 [==============================] - 190s 142ms/step - loss: 0.2079 - accuracy: 0.9330 - val_loss: 1.0925 - val_accuracy: 0.7218\n",
      "Epoch 13/13\n",
      "1336/1336 [==============================] - 191s 143ms/step - loss: 0.1815 - accuracy: 0.9416 - val_loss: 1.0455 - val_accuracy: 0.7273\n",
      "Predicting model 0\n",
      "1407/1407 - 55s - 55s/epoch - 39ms/step\n",
      "Accuracy: 0.7229444444444444 for model 0\n",
      "Saving model 0\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abbd820259cc45ef8a4001afbead411f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "1336/1336 [==============================] - 226s 146ms/step - loss: 1.2355 - accuracy: 0.5672 - val_loss: 0.9968 - val_accuracy: 0.6458\n",
      "Epoch 2/13\n",
      "1336/1336 [==============================] - 191s 143ms/step - loss: 0.9648 - accuracy: 0.6688 - val_loss: 0.9684 - val_accuracy: 0.6573\n",
      "Epoch 3/13\n",
      "1336/1336 [==============================] - 191s 143ms/step - loss: 0.9481 - accuracy: 0.6727 - val_loss: 1.0181 - val_accuracy: 0.6429\n",
      "Epoch 4/13\n",
      "1336/1336 [==============================] - 191s 143ms/step - loss: 0.8401 - accuracy: 0.7119 - val_loss: 0.8374 - val_accuracy: 0.7091\n",
      "Epoch 5/13\n",
      "1336/1336 [==============================] - 192s 144ms/step - loss: 0.7881 - accuracy: 0.7305 - val_loss: 0.8687 - val_accuracy: 0.7031\n",
      "Epoch 6/13\n",
      "1336/1336 [==============================] - 192s 144ms/step - loss: 0.7954 - accuracy: 0.7251 - val_loss: 0.7866 - val_accuracy: 0.7331\n",
      "Epoch 7/13\n",
      "1336/1336 [==============================] - 191s 143ms/step - loss: 0.7799 - accuracy: 0.7307 - val_loss: 0.8059 - val_accuracy: 0.7233\n",
      "Epoch 8/13\n",
      "1336/1336 [==============================] - 192s 144ms/step - loss: 0.5723 - accuracy: 0.8042 - val_loss: 0.8250 - val_accuracy: 0.7271\n",
      "Epoch 9/13\n",
      "1336/1336 [==============================] - 192s 144ms/step - loss: 0.4455 - accuracy: 0.8484 - val_loss: 0.9183 - val_accuracy: 0.7264\n",
      "Epoch 10/13\n",
      "1336/1336 [==============================] - 192s 143ms/step - loss: 0.4197 - accuracy: 0.8603 - val_loss: 1.1522 - val_accuracy: 0.6520\n",
      "Epoch 11/13\n",
      "1336/1336 [==============================] - 191s 143ms/step - loss: 0.4824 - accuracy: 0.8362 - val_loss: 0.8587 - val_accuracy: 0.7387\n",
      "Epoch 12/13\n",
      "1336/1336 [==============================] - 191s 143ms/step - loss: 0.2894 - accuracy: 0.9055 - val_loss: 0.9484 - val_accuracy: 0.7347\n",
      "Epoch 13/13\n",
      "1336/1336 [==============================] - 191s 143ms/step - loss: 0.2351 - accuracy: 0.9226 - val_loss: 0.9758 - val_accuracy: 0.7287\n",
      "Predicting model 1\n",
      "1407/1407 - 55s - 55s/epoch - 39ms/step\n",
      "Accuracy: 0.7230222222222222 for model 1\n",
      "Saving model 1\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592845da14224c48a4dee86e799507b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "1336/1336 [==============================] - 228s 148ms/step - loss: 1.2345 - accuracy: 0.5646 - val_loss: 0.8943 - val_accuracy: 0.6782\n",
      "Epoch 2/13\n",
      "1336/1336 [==============================] - 194s 145ms/step - loss: 0.8739 - accuracy: 0.7002 - val_loss: 0.8615 - val_accuracy: 0.6956\n",
      "Epoch 3/13\n",
      "1336/1336 [==============================] - 193s 145ms/step - loss: 0.7224 - accuracy: 0.7541 - val_loss: 0.8262 - val_accuracy: 0.7278\n",
      "Epoch 4/13\n",
      "1336/1336 [==============================] - 193s 145ms/step - loss: 0.7157 - accuracy: 0.7559 - val_loss: 0.8010 - val_accuracy: 0.7280\n",
      "Epoch 5/13\n",
      "1336/1336 [==============================] - 192s 144ms/step - loss: 0.5850 - accuracy: 0.8037 - val_loss: 0.8319 - val_accuracy: 0.7307\n",
      "Epoch 6/13\n",
      "1336/1336 [==============================] - 193s 144ms/step - loss: 0.6377 - accuracy: 0.7812 - val_loss: 0.8351 - val_accuracy: 0.7136\n",
      "Epoch 7/13\n",
      "1336/1336 [==============================] - 193s 144ms/step - loss: 0.6229 - accuracy: 0.7862 - val_loss: 0.8017 - val_accuracy: 0.7469\n",
      "Epoch 8/13\n",
      "1336/1336 [==============================] - 193s 144ms/step - loss: 0.3835 - accuracy: 0.8713 - val_loss: 0.9222 - val_accuracy: 0.7360\n",
      "Epoch 9/13\n",
      "1336/1336 [==============================] - 194s 145ms/step - loss: 0.3079 - accuracy: 0.8968 - val_loss: 0.8870 - val_accuracy: 0.7402\n",
      "Epoch 10/13\n",
      "1336/1336 [==============================] - 193s 145ms/step - loss: 0.2754 - accuracy: 0.9107 - val_loss: 1.6992 - val_accuracy: 0.7253\n",
      "Epoch 11/13\n",
      "1336/1336 [==============================] - 193s 144ms/step - loss: 0.2475 - accuracy: 0.9185 - val_loss: 1.0432 - val_accuracy: 0.7262\n",
      "Epoch 12/13\n",
      "1336/1336 [==============================] - 193s 145ms/step - loss: 0.2290 - accuracy: 0.9258 - val_loss: 1.0760 - val_accuracy: 0.7376\n",
      "Epoch 13/13\n",
      "1336/1336 [==============================] - 193s 144ms/step - loss: 0.2497 - accuracy: 0.9167 - val_loss: 0.9639 - val_accuracy: 0.7342\n",
      "Predicting model 2\n",
      "1407/1407 - 55s - 55s/epoch - 39ms/step\n",
      "Accuracy: 0.7269444444444444 for model 2\n",
      "Saving model 2\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11b48946c6244c0a75b093b633f2004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "1336/1336 [==============================] - 229s 149ms/step - loss: 1.2760 - accuracy: 0.5457 - val_loss: 0.9979 - val_accuracy: 0.6564\n",
      "Epoch 2/13\n",
      "1336/1336 [==============================] - 195s 146ms/step - loss: 0.9189 - accuracy: 0.6854 - val_loss: 0.9637 - val_accuracy: 0.6640\n",
      "Epoch 3/13\n",
      "1336/1336 [==============================] - 195s 146ms/step - loss: 0.7490 - accuracy: 0.7441 - val_loss: 0.8435 - val_accuracy: 0.7067\n",
      "Epoch 4/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 1.0410 - accuracy: 0.6380 - val_loss: 1.1556 - val_accuracy: 0.5929\n",
      "Epoch 5/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.9357 - accuracy: 0.6719 - val_loss: 0.8294 - val_accuracy: 0.7089\n",
      "Epoch 6/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.6424 - accuracy: 0.7775 - val_loss: 0.8093 - val_accuracy: 0.7284\n",
      "Epoch 7/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.5300 - accuracy: 0.8192 - val_loss: 0.8658 - val_accuracy: 0.7158\n",
      "Epoch 8/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.4610 - accuracy: 0.8434 - val_loss: 0.8889 - val_accuracy: 0.7193\n",
      "Epoch 9/13\n",
      "1336/1336 [==============================] - 195s 146ms/step - loss: 0.4470 - accuracy: 0.8491 - val_loss: 1.1064 - val_accuracy: 0.7169\n",
      "Epoch 10/13\n",
      "1336/1336 [==============================] - 195s 146ms/step - loss: 0.3012 - accuracy: 0.8988 - val_loss: 0.9584 - val_accuracy: 0.7158\n",
      "Epoch 11/13\n",
      "1336/1336 [==============================] - 195s 146ms/step - loss: 0.2631 - accuracy: 0.9127 - val_loss: 0.9759 - val_accuracy: 0.7224\n",
      "Epoch 12/13\n",
      "1336/1336 [==============================] - 195s 146ms/step - loss: 0.2225 - accuracy: 0.9270 - val_loss: 1.0673 - val_accuracy: 0.7156\n",
      "Epoch 13/13\n",
      "1336/1336 [==============================] - 195s 146ms/step - loss: 0.2171 - accuracy: 0.9287 - val_loss: 1.1341 - val_accuracy: 0.7138\n",
      "Predicting model 3\n",
      "1407/1407 - 56s - 56s/epoch - 40ms/step\n",
      "Accuracy: 0.7175555555555555 for model 3\n",
      "Saving model 3\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 85500 files for training.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Using 4500 files for validation.\n",
      "Found 90000 files belonging to 10 classes.\n",
      "Fitting model 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44f62d76c35401aba0824db0c7ea39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "1336/1336 [==============================] - 231s 151ms/step - loss: 1.3002 - accuracy: 0.5304 - val_loss: 1.0034 - val_accuracy: 0.6513\n",
      "Epoch 2/13\n",
      "1336/1336 [==============================] - 197s 147ms/step - loss: 1.1444 - accuracy: 0.5989 - val_loss: 1.0532 - val_accuracy: 0.6218\n",
      "Epoch 3/13\n",
      "1336/1336 [==============================] - 197s 147ms/step - loss: 1.0172 - accuracy: 0.6458 - val_loss: 1.0060 - val_accuracy: 0.6484\n",
      "Epoch 4/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.9004 - accuracy: 0.6863 - val_loss: 0.9175 - val_accuracy: 0.6796\n",
      "Epoch 5/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.9324 - accuracy: 0.6748 - val_loss: 0.9431 - val_accuracy: 0.6878\n",
      "Epoch 6/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.7625 - accuracy: 0.7368 - val_loss: 0.8817 - val_accuracy: 0.7100\n",
      "Epoch 7/13\n",
      "1336/1336 [==============================] - 197s 147ms/step - loss: 0.6780 - accuracy: 0.7668 - val_loss: 1.0126 - val_accuracy: 0.7084\n",
      "Epoch 8/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.5924 - accuracy: 0.7958 - val_loss: 0.9181 - val_accuracy: 0.7127\n",
      "Epoch 9/13\n",
      "1336/1336 [==============================] - 197s 148ms/step - loss: 0.5365 - accuracy: 0.8163 - val_loss: 0.9020 - val_accuracy: 0.7213\n",
      "Epoch 10/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.3961 - accuracy: 0.8663 - val_loss: 1.0098 - val_accuracy: 0.7104\n",
      "Epoch 11/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.3251 - accuracy: 0.8923 - val_loss: 0.9971 - val_accuracy: 0.7111\n",
      "Epoch 12/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.2761 - accuracy: 0.9085 - val_loss: 1.0850 - val_accuracy: 0.7189\n",
      "Epoch 13/13\n",
      "1336/1336 [==============================] - 196s 147ms/step - loss: 0.2251 - accuracy: 0.9269 - val_loss: 1.1344 - val_accuracy: 0.7218\n",
      "Predicting model 4\n",
      "1407/1407 - 61s - 61s/epoch - 43ms/step\n",
      "Accuracy: 0.7234555555555555 for model 4\n",
      "Saving model 4\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 13\n",
    "\n",
    "histories = list()\n",
    "accuracies = list()\n",
    "class_accuracies = list()\n",
    "conf_mats = list()\n",
    "\n",
    "for augs in tqdm(p_dicts, desc=\"Augmentation\"):\n",
    "    aug_str = \"_\".join([key + str(value) for key, value in augs.items()])\n",
    "    print(f\"Augmentations: {aug_str}\")\n",
    "\n",
    "    for iteration in tqdm(range(5), desc=\"Iteration\"):\n",
    "        train_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"../data/CINIC10/train\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            class_names=None,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=batch_size,\n",
    "            image_size=(height, width),\n",
    "            shuffle=True,\n",
    "            seed=iteration,\n",
    "            validation_split=0.05,\n",
    "            subset=\"training\",\n",
    "        )\n",
    "\n",
    "        val_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"../data/CINIC10/valid\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            class_names=None,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=batch_size,\n",
    "            image_size=(height, width),\n",
    "            shuffle=True,\n",
    "            seed=iteration,\n",
    "            validation_split=0.05,\n",
    "            subset=\"validation\",\n",
    "        )\n",
    "\n",
    "        test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            \"../data/CINIC10/test\",\n",
    "            labels=\"inferred\",\n",
    "            label_mode=\"int\",\n",
    "            class_names=None,\n",
    "            color_mode=\"rgb\",\n",
    "            batch_size=batch_size,\n",
    "            image_size=(height, width),\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        dnn_model = Sequential()\n",
    "        imported_model = tf.keras.applications.EfficientNetV2L(\n",
    "            include_top=False,\n",
    "            input_shape=(height, width, 3),\n",
    "            pooling=\"max\",\n",
    "            classes=10,\n",
    "            weights=\"imagenet\",\n",
    "        )\n",
    "\n",
    "        dnn_model.add(imported_model)\n",
    "        dnn_model.add(Flatten())\n",
    "        dnn_model.add(Dense(2048, activation=\"relu\"))\n",
    "        dnn_model.add(Dense(1024, activation=\"relu\"))\n",
    "        dnn_model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "        dnn_model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "       \n",
    "\n",
    "        history = {\n",
    "            \"loss\": list(),\n",
    "            \"accuracy\": list(),\n",
    "            \"val_loss\": list(),\n",
    "            \"val_accuracy\": list(),\n",
    "        }\n",
    "\n",
    "        print(f\"Fitting model {iteration}\")\n",
    "        for epoch in tqdm(range(EPOCHS), desc=\"Epoch\"):\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "            custom_aug = CustomAugmentationsTF(augs)\n",
    "            train_set_aug = train_set.map(lambda x, y: (custom_aug.augment(x), y))\n",
    "\n",
    "            hist_ = dnn_model.fit(train_set_aug, validation_data=val_set, epochs=1)\n",
    "            history[\"loss\"].append(hist_.history[\"loss\"])\n",
    "            history[\"accuracy\"].append(hist_.history[\"accuracy\"])\n",
    "            history[\"val_loss\"].append(hist_.history[\"val_loss\"])\n",
    "            history[\"val_accuracy\"].append(hist_.history[\"val_accuracy\"])\n",
    "\n",
    "        print(f\"Predicting model {iteration}\")\n",
    "        preds = dnn_model.predict(test_set, verbose=2)\n",
    "        preds = preds.argmax(axis=1)\n",
    "        classes = test_set.class_names\n",
    "        test_labels = list()\n",
    "        for images, labels in test_set:\n",
    "            class_labels = [int(label) for label in labels]\n",
    "            test_labels.extend(class_labels)\n",
    "        test_labels = np.array(test_labels)\n",
    "\n",
    "        conf_mat = confusion_matrix(test_labels, preds)\n",
    "        accuracy = accuracy_score(test_labels, preds)\n",
    "        print(f\"Accuracy: {accuracy} for model {iteration}\")\n",
    "        class_accuracy = conf_mat.diagonal() / conf_mat.sum(axis=1)\n",
    "\n",
    "        print(f\"Saving model {iteration}\")\n",
    "        dnn_model.save(f\"../models/EfficientNet_13epochs_aug_{aug_str}_{iteration}.h5\")\n",
    "        histories.append(deepcopy(history))\n",
    "        accuracies.append(deepcopy(accuracy))\n",
    "        class_accuracies.append(deepcopy(class_accuracy))\n",
    "        conf_mats.append(deepcopy(conf_mat))\n",
    "\n",
    "\n",
    "    with open(f\"results/HISTORY_EfficientNet_13epochs_aug_{aug_str}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(histories, f)\n",
    "\n",
    "    with open(f\"results/ACCURACY_EfficientNet_13epochs_aug_{aug_str}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(accuracies, f)\n",
    "\n",
    "    with open(f\"results/CLASS_ACCURACY_EfficientNet_13epochs_aug_{aug_str}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(class_accuracies, f)\n",
    "\n",
    "    with open(f\"results/CONF_MAT_EfficientNet_13epochs_aug_{aug_str}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(conf_mats, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
